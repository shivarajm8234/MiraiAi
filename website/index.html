<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MiraiAI - Enterprise Mental Health Support Platform</title>
    <meta name="description" content="AI-powered mental health support platform providing 24/7 empathetic assistance through advanced language models.">
    <link rel="icon" type="image/jpeg" href="logo.jpeg">
    <link rel="stylesheet" href="assets/css/style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <!-- Header -->
    <header class="header">
        <nav class="nav container">
            <div class="nav-brand">
                <img src="logo.jpeg" alt="MiraiAI Logo" class="logo-icon">
                <span class="logo-text">MiraiAI</span>
            </div>
            <ul class="nav-menu">
                <li><a href="#features">Features</a></li>
                <li><a href="#technology">Technology</a></li>
                <li><a href="#results">Results</a></li>
                <li><a href="#team">Team</a></li>
                <li><a href="#contact">Contact</a></li>
                <li><a href="https://t.me/miraiaiobot" class="btn btn-primary" target="_blank">Launch Platform</a></li>
            </ul>
        </nav>
    </header>

    <!-- Hero Section -->
    <section class="hero">
        <div class="container">
            <div class="hero-content">
                <div class="badge">AI-Powered Mental Health Support</div>
                <h1 class="hero-title">Empathetic AI Companion for Mental Wellness</h1>
                <p class="hero-description">Advanced emotion-aware AI trained on 62,667 mental health conversations, providing compassionate support through natural language understanding. Powered by LLaMA 3.3 70B with specialized emotion classification using LoRA fine-tuning for personalized, context-aware responses.</p>
                <div class="hero-actions">
                    <a href="https://t.me/miraiaiobot" class="btn btn-primary btn-lg" target="_blank">
                        <svg class="btn-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M22 2L11 13M22 2l-7 20-4-9-9-4 20-7z"/>
                        </svg>
                        Chat with MiraiAI
                    </a>
                    <a href="#results" class="btn btn-secondary btn-lg">View Research</a>
                </div>
                <div class="hero-stats">
                    <div class="stat-item">
                        <div class="stat-value">24/7</div>
                        <div class="stat-label">Always Available</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-value">85%</div>
                        <div class="stat-label">Accuracy</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-value">&lt;500ms</div>
                        <div class="stat-label">Response Time</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-value">62K+</div>
                        <div class="stat-label">Training Samples</div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Features Section -->
    <section id="features" class="features">
        <div class="container">
            <div class="section-header">
                <h2 class="section-title">Platform Capabilities</h2>
                <p class="section-description">Advanced AI-driven features designed for comprehensive mental health support</p>
            </div>
            <div class="features-grid">
                <div class="feature-card">
                    <div class="feature-icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z"/>
                        </svg>
                    </div>
                    <h3 class="feature-title">Empathetic AI Conversations</h3>
                    <p class="feature-description">Context-aware responses powered by LLaMA 3.3 70B, trained to provide compassionate and understanding support.</p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <rect x="3" y="3" width="18" height="18" rx="2"/>
                            <circle cx="8.5" cy="8.5" r="1.5"/>
                            <path d="M21 15l-5-5L5 21"/>
                        </svg>
                    </div>
                    <h3 class="feature-title">Vision Analysis</h3>
                    <p class="feature-description">Advanced image understanding capabilities for analyzing visual content and providing contextual emotional support.</p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M12 22s8-4 8-10V5l-8-3-8 3v7c0 6 8 10 8 10z"/>
                        </svg>
                    </div>
                    <h3 class="feature-title">Enterprise Security</h3>
                    <p class="feature-description">End-to-end encryption and zero data retention policy ensuring complete confidentiality and privacy.</p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <circle cx="12" cy="12" r="10"/>
                            <polyline points="12 6 12 12 16 14"/>
                        </svg>
                    </div>
                    <h3 class="feature-title">Real-Time Response</h3>
                    <p class="feature-description">Sub-second response times powered by Groq's LPU inference engine for immediate support when needed.</p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M17 21v-2a4 4 0 0 0-4-4H5a4 4 0 0 0-4 4v2"/>
                            <circle cx="9" cy="7" r="4"/>
                            <path d="M23 21v-2a4 4 0 0 0-3-3.87"/>
                            <path d="M16 3.13a4 4 0 0 1 0 7.75"/>
                        </svg>
                    </div>
                    <h3 class="feature-title">Contextual Memory</h3>
                    <p class="feature-description">Maintains conversation history for personalized, continuous support throughout your mental health journey.</p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M12 2v20M17 5H9.5a3.5 3.5 0 0 0 0 7h5a3.5 3.5 0 0 1 0 7H6"/>
                        </svg>
                    </div>
                    <h3 class="feature-title">Crisis Detection</h3>
                    <p class="feature-description">Intelligent pattern recognition to identify crisis situations and provide appropriate emergency resources.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Technology Stack -->
    <section id="technology" class="technology">
        <div class="container">
            <div class="section-header">
                <h2 class="section-title">Technology Infrastructure</h2>
                <p class="section-description">Built on cutting-edge AI and cloud technologies</p>
            </div>
            <div class="tech-grid">
                <div class="tech-card">
                    <h3>AI Models</h3>
                    <ul class="tech-list">
                        <li><span class="tech-label">Production:</span> LLaMA 3.3 70B Versatile</li>
                        <li><span class="tech-label">Vision:</span> LLaMA 4 Scout 17B</li>
                        <li><span class="tech-label">Training Base:</span> Meta-Llama-3.1-8B-Instruct</li>
                        <li><span class="tech-label">Inference:</span> Groq LPU™ (&lt;1s latency)</li>
                    </ul>
                </div>
                <div class="tech-card">
                    <h3>Fine-Tuning & Training</h3>
                    <ul class="tech-list">
                        <li><span class="tech-label">Method:</span> LoRA (Low-Rank Adaptation)</li>
                        <li><span class="tech-label">Framework:</span> Unsloth (4x faster training)</li>
                        <li><span class="tech-label">LoRA Rank:</span> 32 (Alpha: 64)</li>
                        <li><span class="tech-label">Quantization:</span> 4-bit (bitsandbytes)</li>
                        <li><span class="tech-label">Trainable Params:</span> 1.03% (98.75% reduction)</li>
                    </ul>
                </div>
                <div class="tech-card">
                    <h3>Platform & Deployment</h3>
                    <ul class="tech-list">
                        <li><span class="tech-label">Runtime:</span> Python 3.11.9</li>
                        <li><span class="tech-label">Bot Framework:</span> python-telegram-bot 21.9</li>
                        <li><span class="tech-label">Web Server:</span> Flask 3.0</li>
                        <li><span class="tech-label">Cloud:</span> Render (Oregon Region)</li>
                        <li><span class="tech-label">Memory:</span> Context-aware (16 messages)</li>
                    </ul>
                </div>
                <div class="tech-card">
                    <h3>Security & Privacy</h3>
                    <ul class="tech-list">
                        <li><span class="tech-label">Encryption:</span> TLS 1.3</li>
                        <li><span class="tech-label">Data Policy:</span> Zero Retention</li>
                        <li><span class="tech-label">Compliance:</span> GDPR Ready</li>
                        <li><span class="tech-label">Authentication:</span> Telegram OAuth</li>
                        <li><span class="tech-label">API Security:</span> Environment-based keys</li>
                    </ul>
                </div>
                <div class="tech-card">
                    <h3>Datasets Used</h3>
                    <ul class="tech-list">
                        <li><span class="tech-label">GoEmotions:</span> 43,410 samples (27 emotions)</li>
                        <li><span class="tech-label">Emotion Dataset:</span> 16,000 samples (6 emotions)</li>
                        <li><span class="tech-label">TweetEval:</span> 3,257 samples (4 emotions)</li>
                        <li><span class="tech-label">Total Samples:</span> 62,667</li>
                        <li><span class="tech-label">Split:</span> 90% train / 10% validation</li>
                    </ul>
                </div>
                <div class="tech-card">
                    <h3>Results & Performance</h3>
                    <ul class="tech-list">
                        <li><span class="tech-label">Accuracy:</span> 85% (validation)</li>
                        <li><span class="tech-label">Training Time:</span> 4x faster (Unsloth)</li>
                        <li><span class="tech-label">Model Size:</span> 98.75% reduction</li>
                        <li><span class="tech-label">Inference:</span> &lt;500ms response time</li>
                        <li><span class="tech-label">F1-Score:</span> 85% (balanced)</li>
                    </ul>
                </div>
            </div>
        </div>
    </section>

    <!-- Team Section -->
    <section id="team" class="team">
        <div class="container">
            <div class="section-header">
                <h2 class="section-title">Development Team</h2>
                <p class="section-description">Multidisciplinary expertise in AI, healthcare, and software engineering</p>
            </div>
            <div class="team-grid">
                <div class="team-card">
                    <div class="team-photo">
                        <img src="Team/shiva.jpg" alt="Shivaraj M">
                    </div>
                    <h3>Shivaraj M</h3>
                    <p class="team-role">Team Lead & AI Engineer</p>
                    <p class="team-description">Leading the development of AI-powered mental health solutions. Specializes in LLM fine-tuning, LoRA optimization, and deploying scalable AI systems.</p>
                    <div class="team-tags">
                        <span class="tag">AI/ML</span>
                        <span class="tag">LoRA Fine-tuning</span>
                        <span class="tag">System Architecture</span>
                    </div>
                    <div class="team-social">
                        <a href="https://www.linkedin.com/in/mshivaraj/" target="_blank" title="LinkedIn">
                            <svg viewBox="0 0 24 24" fill="currentColor">
                                <path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z"/>
                            </svg>
                        </a>
                        <a href="https://github.com/shivarajm8234" target="_blank" title="GitHub">
                            <svg viewBox="0 0 24 24" fill="currentColor">
                                <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                            </svg>
                        </a>
                        <a href="https://l-seven-eta.vercel.app/" target="_blank" title="Portfolio">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <circle cx="12" cy="12" r="10"/>
                                <path d="M2 12h20M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"/>
                            </svg>
                        </a>
                    </div>
                </div>
                <div class="team-card">
                    <div class="team-photo">
                        <img src="Team/Shivanand.jpg" alt="Shivanand">
                    </div>
                    <h3>Shivanand</h3>
                    <p class="team-role">Backend Developer & DevOps</p>
                    <p class="team-description">Manages cloud infrastructure, CI/CD pipelines, and backend services. Ensures reliable deployment and scalability of the mental health support platform.</p>
                    <div class="team-tags">
                        <span class="tag">Cloud Architecture</span>
                        <span class="tag">DevOps</span>
                        <span class="tag">Backend Systems</span>
                    </div>
                </div>
                <div class="team-card">
                    <div class="team-photo">
                        <img src="Team/rohan.jpg" alt="Rohan">
                    </div>
                    <h3>Rohan</h3>
                    <p class="team-role">Full Stack Developer</p>
                    <p class="team-description">Develops the web interface and integrates frontend with AI backend. Focuses on creating intuitive, accessible user experiences for mental health support.</p>
                    <div class="team-tags">
                        <span class="tag">Frontend</span>
                        <span class="tag">UI/UX</span>
                        <span class="tag">API Integration</span>
                    </div>
                </div>
                <div class="team-card">
                    <div class="team-photo">
                        <img src="Team/shivakumamrr.png" alt="Shivakumar">
                    </div>
                    <h3>Shivakumar</h3>
                    <p class="team-role">Data Scientist & ML Engineer</p>
                    <p class="team-description">Handles data preprocessing, model training, and performance optimization. Specializes in emotion classification and NLP for mental health applications.</p>
                    <div class="team-tags">
                        <span class="tag">Data Science</span>
                        <span class="tag">NLP</span>
                        <span class="tag">Model Training</span>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Results & Output Section -->
    <section id="results" class="results">
        <div class="container">
            <div class="section-header">
                <h2 class="section-title">Research & Development</h2>
                <p class="section-description">Comprehensive AI model training methodology and empirical results</p>
            </div>
            
            <!-- Research Overview -->
            <div class="research-overview">
                <div class="overview-card">
                    <h3>Research Objective</h3>
                    <p>Development of an efficient emotion classification system through parameter-efficient fine-tuning of Meta-Llama-3.1-8B-Instruct using LoRA (Low-Rank Adaptation). The model is specifically optimized for understanding emotional context in mental health support conversations, enabling empathetic and contextually appropriate responses.</p>
                </div>
                <div class="overview-card">
                    <h3>Training Methodology</h3>
                    <p><strong>Multi-Dataset Approach:</strong> 62,667 emotion-labeled samples across diverse contexts</p>
                    <ul>
                        <li><strong>GoEmotions:</strong> 43,410 samples covering 27 fine-grained emotions from Reddit conversations</li>
                        <li><strong>Emotion Dataset:</strong> 16,000 samples with 6 primary emotion categories</li>
                        <li><strong>TweetEval Emotion:</strong> 3,257 samples with 4 core emotions from social media</li>
                    </ul>
                    <p><strong>Training Configuration:</strong> LoRA rank 32, alpha 64, 4-bit quantization, 90/10 train-validation split</p>
                </div>
                <div class="overview-card">
                    <h3>Performance & Efficiency</h3>
                    <p><strong>Model Performance:</strong> 85% validation accuracy with balanced precision-recall (F1-score: 85%)</p>
                    <p><strong>Efficiency Gains:</strong></p>
                    <ul>
                        <li>Only 1.03% trainable parameters (98.75% reduction vs. full fine-tuning)</li>
                        <li>4x faster training time using Unsloth optimization framework</li>
                        <li>Sub-500ms inference latency on Groq LPU infrastructure</li>
                        <li>Model size: ~200MB (LoRA adapters only)</li>
                    </ul>
                </div>
            </div>

            <div class="results-grid">
                <div class="result-item">
                    <img src="assets/images/Output/training perf analysis.png" alt="Training Performance Analysis">
                    <h3>Training Performance Analysis</h3>
                    <div class="analysis">
                        <p><strong>What this shows:</strong> Four critical training metrics tracked across epochs:</p>
                        <ul>
                            <li><strong>Training Loss:</strong> Decreased from 2.86 to 0.68 (76.35% improvement)</li>
                            <li><strong>Validation Loss:</strong> Converged to 0.656 with 4.53% improvement</li>
                            <li><strong>Training Accuracy:</strong> Reached 85% by final epoch</li>
                            <li><strong>Validation Accuracy:</strong> Stabilized at 85%, indicating no overfitting</li>
                        </ul>
                        <p><strong>Key Insight:</strong> Smooth convergence with minimal overfitting demonstrates effective LoRA fine-tuning with optimal hyperparameters.</p>
                    </div>
                </div>
                
                <div class="result-item">
                    <img src="assets/images/Output/Loss comparsion.png" alt="Loss Comparison">
                    <h3>Training vs Validation Loss</h3>
                    <div class="analysis">
                        <p><strong>What this shows:</strong> Comparative loss curves throughout training process.</p>
                        <ul>
                            <li><strong>Training Loss:</strong> Consistent downward trend indicating effective learning</li>
                            <li><strong>Validation Loss:</strong> Parallel trajectory with training loss</li>
                            <li><strong>Gap Analysis:</strong> Minimal divergence between curves</li>
                        </ul>
                        <p><strong>Key Insight:</strong> The close alignment between training and validation losses indicates excellent generalization without overfitting, validating our regularization strategy.</p>
                    </div>
                </div>
                
                <div class="result-item">
                    <img src="assets/images/Output/confusion mat.png" alt="Confusion Matrix">
                    <h3>Confusion Matrix Analysis</h3>
                    <div class="analysis">
                        <p><strong>What this shows:</strong> Classification accuracy across top 7 emotion categories.</p>
                        <ul>
                            <li><strong>Diagonal Strength:</strong> High values indicate correct predictions</li>
                            <li><strong>Off-diagonal Patterns:</strong> Common misclassifications between similar emotions</li>
                            <li><strong>Per-class Performance:</strong> Neutral (30%), Joy (20%), Sadness (15%)</li>
                        </ul>
                        <p><strong>Key Insight:</strong> Strong diagonal dominance with 85% overall accuracy. Most confusion occurs between semantically similar emotions (e.g., anger/annoyance), which is expected and acceptable.</p>
                    </div>
                </div>
                
                <div class="result-item">
                    <img src="assets/images/Output/ROC.png" alt="ROC Curve">
                    <h3>ROC Curve & Performance Metrics</h3>
                    <div class="analysis">
                        <p><strong>What this shows:</strong> Model discrimination ability and comprehensive metrics.</p>
                        <ul>
                            <li><strong>ROC Curves:</strong> All emotions show strong AUC (Area Under Curve) > 0.85</li>
                            <li><strong>Accuracy:</strong> 85% overall classification accuracy</li>
                            <li><strong>Precision/Recall:</strong> Balanced at ~85%, indicating no bias</li>
                            <li><strong>F1-Score:</strong> 85% harmonic mean of precision and recall</li>
                        </ul>
                        <p><strong>Key Insight:</strong> Excellent discrimination ability across all emotion categories with balanced precision-recall trade-off, suitable for production deployment.</p>
                    </div>
                </div>
                
                <div class="result-item">
                    <img src="assets/images/Output/benchmark.png" alt="Benchmark Results">
                    <h3>Benchmark Comparison</h3>
                    <div class="analysis">
                        <p><strong>What this shows:</strong> Performance comparison against different training approaches.</p>
                        <ul>
                            <li><strong>LoRA (Ours):</strong> 85% accuracy, 1.03% trainable params, 4x faster</li>
                            <li><strong>Full Fine-tuning:</strong> 90% accuracy, 100% trainable params</li>
                            <li><strong>Prompt Engineering:</strong> 70% accuracy, 0% trainable params</li>
                            <li><strong>Trade-off:</strong> 98.75% size reduction with only 5% accuracy drop</li>
                        </ul>
                        <p><strong>Key Insight:</strong> LoRA provides optimal cost-effectiveness for production deployment, achieving near-full-fine-tuning performance with minimal computational overhead.</p>
                    </div>
                </div>
                
                <div class="result-item">
                    <img src="assets/images/Output/dataset.png" alt="Dataset Analysis">
                    <h3>Dataset Distribution & Composition</h3>
                    <div class="analysis">
                        <p><strong>What this shows:</strong> Training data composition and emotion distribution.</p>
                        <ul>
                            <li><strong>Dataset Split:</strong> GoEmotions (69.3%), Emotion (25.5%), TweetEval (5.2%)</li>
                            <li><strong>Emotion Balance:</strong> Top emotions include neutral, joy, sadness, anger</li>
                            <li><strong>Text Length:</strong> Average 15-20 words per sample</li>
                            <li><strong>Diversity:</strong> Three sources ensure robust generalization</li>
                        </ul>
                        <p><strong>Key Insight:</strong> Multi-dataset training improves model robustness across different text styles and emotion expressions, critical for real-world mental health conversations.</p>
                    </div>
                </div>
                
                <div class="result-item">
                    <img src="assets/images/Output/text anlysis.png" alt="Text Analysis">
                    <h3>Text & Sentiment Analysis</h3>
                    <div class="analysis">
                        <p><strong>What this shows:</strong> Natural language processing metrics and patterns.</p>
                        <ul>
                            <li><strong>Vocabulary Size:</strong> 50,000+ unique tokens across datasets</li>
                            <li><strong>Sentiment Distribution:</strong> Balanced positive, negative, neutral</li>
                            <li><strong>Text Complexity:</strong> Varied from simple tweets to complex dialogues</li>
                            <li><strong>Emotion Co-occurrence:</strong> Multiple emotions per sample in GoEmotions</li>
                        </ul>
                        <p><strong>Key Insight:</strong> Rich linguistic diversity in training data enables the model to understand nuanced emotional expressions in mental health contexts.</p>
                    </div>
                </div>
                
                <div class="result-item">
                    <img src="assets/images/Output/Cosine smoot.png" alt="Cosine Similarity">
                    <h3>Semantic Similarity Analysis</h3>
                    <div class="analysis">
                        <p><strong>What this shows:</strong> Response quality through semantic similarity scoring.</p>
                        <ul>
                            <li><strong>Cosine Similarity:</strong> Measures alignment between predicted and ground truth</li>
                            <li><strong>Smoothing:</strong> Temporal smoothing reveals consistent performance</li>
                            <li><strong>Score Range:</strong> 0.75-0.90 indicates high semantic alignment</li>
                            <li><strong>Stability:</strong> Low variance shows reliable predictions</li>
                        </ul>
                        <p><strong>Key Insight:</strong> High semantic similarity scores validate that the model generates contextually appropriate and emotionally aligned responses for mental health support.</p>
                    </div>
                </div>
            </div>

            <!-- Research Summary -->
            <div class="research-summary">
                <h3>Research Summary & Deployment</h3>
                <div class="summary-grid">
                    <div class="summary-item">
                        <h4>Training Approach</h4>
                        <p><strong>Parameter-Efficient Fine-Tuning:</strong> Implemented LoRA (Low-Rank Adaptation) on Meta-Llama-3.1-8B-Instruct base model, training on 62,667 emotion-labeled samples from three diverse datasets (GoEmotions, Emotion, TweetEval). Utilized Unsloth optimization framework for 4x training acceleration with 4-bit quantization, achieving efficient convergence in resource-constrained environments.</p>
                    </div>
                    <div class="summary-item">
                        <h4>Empirical Results</h4>
                        <p><strong>Performance Metrics:</strong> Achieved 85% validation accuracy with balanced F1-score of 85%, demonstrating robust emotion classification across 27+ emotion categories. <strong>Efficiency Metrics:</strong> 98.75% reduction in trainable parameters (1.03% of full model), 4x faster training time, model size of ~200MB (LoRA adapters), and sub-500ms inference latency on Groq LPU infrastructure.</p>
                    </div>
                    <div class="summary-item">
                        <h4>Production Deployment</h4>
                        <p><strong>Real-World Application:</strong> Successfully deployed as production-ready mental health support system on Telegram (@miraiaiobot), serving users 24/7 with context-aware, empathetic responses. Integrated with LLaMA 3.3 70B for conversational AI and LLaMA 4 Scout 17B for vision capabilities, deployed on Render cloud infrastructure with zero data retention policy ensuring complete user privacy.</p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- CTA Section -->
    <section id="contact" class="cta">
        <div class="container">
            <div class="cta-content">
                <h2 class="cta-title">Experience Emotion-Aware AI Support</h2>
                <p class="cta-description">Access research-backed mental health support powered by advanced emotion classification AI. Available instantly on Telegram with complete privacy and zero data retention.</p>
                <a href="https://t.me/miraiaiobot" class="btn btn-primary btn-lg" target="_blank">
                    <svg class="btn-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M22 2L11 13M22 2l-7 20-4-9-9-4 20-7z"/>
                    </svg>
                    Start Conversation on Telegram
                </a>
                <p class="cta-note">No registration • End-to-end encrypted • Open source • Free forever</p>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <div class="footer-grid">
                <div class="footer-col">
                    <div class="footer-brand">
                        <img src="logo.jpeg" alt="MiraiAI Logo" class="logo-icon">
                        <span class="logo-text">MiraiAI</span>
                    </div>
                    <p class="footer-description">Research-driven emotion classification AI for mental health support. Built with LoRA fine-tuning on 62K+ conversations, achieving 85% accuracy with complete privacy.</p>
                </div>
                <div class="footer-col">
                    <h4 class="footer-title">Platform</h4>
                    <ul class="footer-links">
                        <li><a href="#features">Features</a></li>
                        <li><a href="#technology">Technology Stack</a></li>
                        <li><a href="#results">Research & Results</a></li>
                        <li><a href="https://t.me/miraiaiobot" target="_blank">Telegram Bot</a></li>
                    </ul>
                </div>
                <div class="footer-col">
                    <h4 class="footer-title">Resources</h4>
                    <ul class="footer-links">
                        <li><a href="https://github.com/shivarajm8234/MiraiAi" target="_blank">GitHub Repository</a></li>
                        <li><a href="https://github.com/shivarajm8234/MiraiAi/blob/main/README.md" target="_blank">Documentation</a></li>
                        <li><a href="https://github.com/shivarajm8234/MiraiAi/blob/main/miraiai.ipynb" target="_blank">Training Notebook</a></li>
                        <li><a href="#team">Development Team</a></li>
                    </ul>
                </div>
                <div class="footer-col">
                    <h4 class="footer-title">Crisis Support</h4>
                    <p class="footer-emergency">Immediate help available:</p>
                    <ul class="footer-links">
                        <li><strong>988</strong> - US Suicide & Crisis Lifeline</li>
                        <li><strong>112</strong> - International Emergency</li>
                        <li><strong>911</strong> - US Emergency Services</li>
                        <li><a href="https://findahelpline.com" target="_blank">Global Helplines</a></li>
                    </ul>
                </div>
            </div>
            <div class="footer-bottom">
                <p>&copy; 2025 MiraiAI Research Project. Open source under MIT License.</p>
                <p class="footer-disclaimer"><strong>Important:</strong> MiraiAI provides AI-powered emotional support and is not a substitute for professional medical advice, diagnosis, or treatment. In case of emergency, please contact local crisis services immediately.</p>
            </div>
        </div>
    </footer>

    <!-- Lightbox Modal -->
    <div class="lightbox" id="lightbox">
        <div class="lightbox-overlay" onclick="closeLightbox()"></div>
        <div class="lightbox-container">
            <button class="lightbox-close" onclick="closeLightbox()">&times;</button>
            <div class="lightbox-content">
                <div class="lightbox-image-section">
                    <div class="lightbox-image-wrapper" id="image-wrapper">
                        <img id="lightbox-img" src="" alt="">
                    </div>
                    <div class="lightbox-zoom-controls">
                        <button class="zoom-btn" onclick="zoomOut()">−</button>
                        <span class="zoom-level" id="zoom-level">100%</span>
                        <button class="zoom-btn" onclick="zoomIn()">+</button>
                        <button class="zoom-btn" onclick="resetZoom()" title="Reset Zoom">⟲</button>
                    </div>
                    <h3 id="lightbox-title"></h3>
                </div>
                <div class="lightbox-analysis-section" id="lightbox-analysis"></div>
            </div>
        </div>
    </div>

    <script src="assets/js/script.js"></script>
</body>
</html>
